import requests
from bs4 import BeautifulSoup
import re
import json
import base64
from io import BytesIO
from docx import Document
from docx.shared import Inches
import os

# CÃ¡c field cáº§n láº¥y (trá»« MÃ£ sá»‘ thuáº¿, SÄT sáº½ xá»­ lÃ½ riÃªng)
DETAIL_FIELDS = {
    "TÃªn giao dá»‹ch": r"TÃªn giao dá»‹ch:\s*(.+)",
    "Äá»‹a chá»‰": r"Äá»‹a chá»‰:\s*(.+)",
    "Äáº¡i diá»‡n phÃ¡p luáº­t": r"Äáº¡i diá»‡n phÃ¡p luáº­t:\s*(.+)",
    "NgÃ y cáº¥p giáº¥y phÃ©p": r"NgÃ y cáº¥p giáº¥y phÃ©p:\s*(.+)",
    "NgÃ y hoáº¡t Ä‘á»™ng": r"NgÃ y hoáº¡t Ä‘á»™ng:\s*(.+)",
    "Tráº¡ng thÃ¡i": r"Tráº¡ng thÃ¡i:\s*(.+)"
}

def add_base64_image(doc, base64_str, width=1.2):
    """Giáº£i mÃ£ áº£nh base64 vÃ  chÃ¨n vÃ o docx"""
    try:
        if base64_str.startswith("data:image"):
            base64_str = base64_str.split(",")[1]
        img_data = base64.b64decode(base64_str)
        image_stream = BytesIO(img_data)
        doc.add_picture(image_stream, width=Inches(width))
    except Exception as e:
        doc.add_paragraph(f"[Lá»—i áº£nh: {e}]")

def get_company_detail(url):
    res = requests.get(url)
    soup = BeautifulSoup(res.text, "html.parser")
    
    info = {"url": url, "soup": soup}
    block = soup.select_one("div.jumbotron")
    if block:
        text = block.get_text("\n", strip=True)

        # láº¥y cÃ¡c field text
        for field, pattern in DETAIL_FIELDS.items():
            match = re.search(pattern, text)
            if match:
                info[field] = match.group(1).strip()

    return info

def next_docx_name(base_name, folder, ext=".docx"):
    """
    Sinh tÃªn file theo bá»™ Ä‘áº¿m tÄƒng dáº§n: base_name_1.docx, base_name_2.docx, ...
    """
    files = os.listdir(folder)
    numbers = []
    for f in files:
        if f.startswith(base_name) and f.endswith(ext):
            parts = f.replace(ext, "").split("_")
            if len(parts) > 1 and parts[-1].isdigit():
                numbers.append(int(parts[-1]))
    next_num = max(numbers) + 1 if numbers else 1
    return os.path.join(folder, f"{base_name}_{next_num}{ext}")

if __name__ == "__main__":
    # Äá»c danh sÃ¡ch link cÃ´ng ty
    with open("companies_links_page_12_13.json", "r", encoding="utf-8") as f:
        companies = json.load(f)
    
    # Táº¡o file Word
    doc = Document()

    for comp in companies:
        if comp["ten_cong_ty"].strip().upper().startswith("UBND"):
            continue
        print("ğŸ“Œ Äang láº¥y:", comp["ten_cong_ty"])
        detail = get_company_detail(comp["url"])
        soup = detail["soup"]

        # --- Ghi vÃ o Word ---
        doc.add_heading(comp["ten_cong_ty"], level=1)

        if "Äá»‹a chá»‰" in detail:
            doc.add_paragraph(f"Äá»‹a chá»‰: {detail['Äá»‹a chá»‰']}")
        if "NgÃ y hoáº¡t Ä‘á»™ng" in detail:
            doc.add_paragraph(f"NgÃ y hoáº¡t Ä‘á»™ng: {detail['NgÃ y hoáº¡t Ä‘á»™ng']}")
        if "Äáº¡i diá»‡n phÃ¡p luáº­t" in detail:
            doc.add_paragraph(f"Äáº¡i diá»‡n phÃ¡p luáº­t: {detail['Äáº¡i diá»‡n phÃ¡p luáº­t']}")

        # xá»­ lÃ½ áº£nh base64 (thÆ°á»ng cÃ³ 2 áº£nh: mÃ£ sá»‘ thuáº¿, sá»‘ Ä‘iá»‡n thoáº¡i)
        imgs = soup.select("img")

        # --- MÃ£ sá»‘ thuáº¿ ---
        if imgs and len(imgs) > 0 and imgs[0].get("src", "").startswith("data:image"):
            doc.add_paragraph("MÃ£ sá»‘ thuáº¿: ")
            add_base64_image(doc, imgs[0]["src"], width=1.2)
        elif "MÃ£ sá»‘ thuáº¿" in detail:
            doc.add_paragraph(f"MÃ£ sá»‘ thuáº¿: {detail['MÃ£ sá»‘ thuáº¿']}")

        # --- Sá»‘ Ä‘iá»‡n thoáº¡i ---
        if imgs and len(imgs) > 1 and imgs[1].get("src", "").startswith("data:image"):
            doc.add_paragraph("Sá»‘ Ä‘iá»‡n thoáº¡i: ")
            add_base64_image(doc, imgs[1]["src"], width=1.0)
        elif "Äiá»‡n thoáº¡i trá»¥ sá»Ÿ" in detail:
            doc.add_paragraph(f"Sá»‘ Ä‘iá»‡n thoáº¡i: {detail['Äiá»‡n thoáº¡i trá»¥ sá»Ÿ']}")

        doc.add_paragraph("-------------------------")

    # Xuáº¥t ra file vá»›i tÃªn tá»± tÄƒng
    output_folder = "."   # thÆ° má»¥c hiá»‡n táº¡i, báº¡n cÃ³ thá»ƒ Ä‘á»•i thÃ nh "D:/output"
    file_path = next_docx_name("companies_output", output_folder)
    doc.save(file_path)
    print(f"âœ… ÄÃ£ xuáº¥t ra {file_path}")
